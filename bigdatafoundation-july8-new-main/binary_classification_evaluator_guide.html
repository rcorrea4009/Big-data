<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Binary Classification Evaluator Guide</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
        }
        
        .container {
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }
        
        h1 {
            color: #2c3e50;
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        }
        
        .section {
            margin: 30px 0;
            padding: 20px;
            border-radius: 10px;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            border-left: 5px solid #3498db;
        }
        
        .step-header {
            color: #2980b9;
            font-size: 1.4em;
            margin-bottom: 15px;
            font-weight: bold;
        }
        
        .code-block {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 15px;
            border-radius: 8px;
            font-family: 'Consolas', 'Monaco', monospace;
            overflow-x: auto;
            margin: 15px 0;
        }
        
        .highlight {
            background: #fff3cd;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #ffc107;
            margin: 15px 0;
        }
        
        .visual-example {
            background: #fff;
            padding: 20px;
            border-radius: 10px;
            border: 2px solid #3498db;
            margin: 15px 0;
        }
        
        .confusion-matrix {
            display: grid;
            grid-template-columns: 120px 120px 120px;
            grid-template-rows: 60px 60px 60px;
            gap: 2px;
            margin: 20px auto;
            max-width: 400px;
            text-align: center;
            font-weight: bold;
        }
        
        .matrix-header {
            background: #3498db;
            color: white;
            display: flex;
            align-items: center;
            justify-content: center;
            border-radius: 5px;
        }
        
        .matrix-cell {
            background: #ecf0f1;
            display: flex;
            align-items: center;
            justify-content: center;
            border-radius: 5px;
            font-size: 1.2em;
        }
        
        .tp { background: #2ecc71; color: white; }
        .tn { background: #27ae60; color: white; }
        .fp { background: #e74c3c; color: white; }
        .fn { background: #c0392b; color: white; }
        
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .metric-card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            border: 2px solid #3498db;
            text-align: center;
        }
        
        .metric-title {
            font-size: 1.2em;
            font-weight: bold;
            color: #2c3e50;
            margin-bottom: 10px;
        }
        
        .metric-formula {
            background: #e8f4fd;
            padding: 10px;
            border-radius: 5px;
            font-family: 'Consolas', 'Monaco', monospace;
            margin: 10px 0;
        }
        
        .metric-example {
            background: #d4edda;
            padding: 10px;
            border-radius: 5px;
            color: #155724;
            font-weight: bold;
        }
        
        .roc-visualization {
            display: flex;
            justify-content: space-around;
            align-items: center;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        
        .roc-curve {
            width: 300px;
            height: 300px;
            background: white;
            border: 2px solid #3498db;
            border-radius: 10px;
            position: relative;
            margin: 10px;
        }
        
        .roc-curve canvas {
            width: 100%;
            height: 100%;
        }
        
        .axis-labels {
            position: absolute;
            font-size: 0.9em;
            color: #2c3e50;
            font-weight: bold;
        }
        
        .x-axis { bottom: 5px; left: 50%; transform: translateX(-50%); }
        .y-axis { left: 5px; top: 50%; transform: rotate(-90deg); }
        
        .curve-perfect {
            position: absolute;
            top: 10%;
            left: 10%;
            width: 80%;
            height: 80%;
            border-left: 3px solid #27ae60;
            border-top: 3px solid #27ae60;
        }
        
        .curve-good {
            position: absolute;
            top: 10%;
            left: 10%;
            width: 80%;
            height: 80%;
            border: 2px solid #f39c12;
            border-radius: 0 0 50% 0;
            border-top: none;
            border-right: none;
        }
        
        .curve-random {
            position: absolute;
            top: 10%;
            left: 10%;
            width: 80%;
            height: 80%;
            border-top: 2px dashed #e74c3c;
            transform: rotate(45deg);
            transform-origin: bottom left;
        }
        
        .banking-example {
            background: #e8f5e8;
            padding: 20px;
            border-radius: 10px;
            border: 2px solid #27ae60;
            margin: 20px 0;
        }
        
        .example-data {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 15px 0;
        }
        
        .data-point {
            background: white;
            padding: 15px;
            border-radius: 8px;
            border: 1px solid #ddd;
        }
        
        .correct-prediction {
            border-left: 4px solid #27ae60;
        }
        
        .wrong-prediction {
            border-left: 4px solid #e74c3c;
        }
        
        .auc-explanation {
            background: #fff;
            padding: 20px;
            border-radius: 10px;
            border: 2px solid #9b59b6;
            margin: 20px 0;
        }
        
        .auc-scale {
            display: flex;
            align-items: center;
            margin: 15px 0;
            background: linear-gradient(90deg, #e74c3c 0%, #f39c12 50%, #27ae60 100%);
            height: 30px;
            border-radius: 15px;
            position: relative;
        }
        
        .scale-marker {
            position: absolute;
            top: -30px;
            font-weight: bold;
            font-size: 0.9em;
        }
        
        .poor { left: 10%; color: #e74c3c; }
        .fair { left: 30%; color: #f39c12; }
        .good { left: 50%; color: #f39c12; }
        .excellent { left: 80%; color: #27ae60; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéØ Binary Classification Evaluator Explained</h1>
        
        <div class="section">
            <div class="step-header">ü§î What is Binary Classification Evaluator?</div>
            
            <div class="highlight">
                <strong>Simple Definition:</strong> It's PySpark's tool for measuring how well your model performs at making yes/no (binary) predictions. Think of it as a "report card" for your machine learning model.
            </div>
            
            <div class="code-block">
from pyspark.ml.evaluation import BinaryClassificationEvaluator

evaluator = BinaryClassificationEvaluator()
auc_score = evaluator.evaluate(predictions)
print(f"Area Under ROC: {auc_score}")
            </div>
            
            <div class="visual-example">
                <h4>üìã What It Does:</h4>
                <ul>
                    <li><strong>Input:</strong> Takes your model's predictions vs. actual results</li>
                    <li><strong>Process:</strong> Calculates various performance metrics</li>
                    <li><strong>Output:</strong> Gives you a score (0.0 to 1.0) indicating model quality</li>
                    <li><strong>Default Metric:</strong> Area Under ROC Curve (AUC)</li>
                </ul>
            </div>
        </div>

        <div class="section">
            <div class="step-header">üè¶ Real Banking Example</div>
            
            <div class="banking-example">
                <h4>üéØ Scenario: Predicting if customers will open an account</h4>
                <p><strong>Goal:</strong> Your bank wants to know who will say "YES" to opening a new account.</p>
                
                <div class="example-data">
                    <div class="data-point correct-prediction">
                        <strong>Customer A</strong><br>
                        Predicted: YES (0.8 probability)<br>
                        Actual: YES ‚úÖ<br>
                        <em>Correct prediction!</em>
                    </div>
                    <div class="data-point correct-prediction">
                        <strong>Customer B</strong><br>
                        Predicted: NO (0.2 probability)<br>
                        Actual: NO ‚úÖ<br>
                        <em>Correct prediction!</em>
                    </div>
                    <div class="data-point wrong-prediction">
                        <strong>Customer C</strong><br>
                        Predicted: YES (0.7 probability)<br>
                        Actual: NO ‚ùå<br>
                        <em>False alarm!</em>
                    </div>
                    <div class="data-point wrong-prediction">
                        <strong>Customer D</strong><br>
                        Predicted: NO (0.3 probability)<br>
                        Actual: YES ‚ùå<br>
                        <em>Missed opportunity!</em>
                    </div>
                </div>
            </div>
        </div>

        <div class="section">
            <div class="step-header">üìä Understanding the Confusion Matrix</div>
            
            <div class="visual-example">
                <h4>üî¢ Breaking Down Predictions</h4>
                <div class="confusion-matrix">
                    <div class="matrix-header"></div>
                    <div class="matrix-header">Predicted: NO</div>
                    <div class="matrix-header">Predicted: YES</div>
                    
                    <div class="matrix-header">Actual: NO</div>
                    <div class="matrix-cell tn">True Negative<br>(TN)<br>85</div>
                    <div class="matrix-cell fp">False Positive<br>(FP)<br>15</div>
                    
                    <div class="matrix-header">Actual: YES</div>
                    <div class="matrix-cell fn">False Negative<br>(FN)<br>10</div>
                    <div class="matrix-cell tp">True Positive<br>(TP)<br>90</div>
                </div>
                
                <div style="margin-top: 20px;">
                    <h5>üìù What each means:</h5>
                    <ul>
                        <li><strong style="color: #2ecc71;">True Positive (TP):</strong> Correctly predicted "YES" - Found real customers!</li>
                        <li><strong style="color: #27ae60;">True Negative (TN):</strong> Correctly predicted "NO" - Avoided wasting effort!</li>
                        <li><strong style="color: #e74c3c;">False Positive (FP):</strong> Wrongly predicted "YES" - Wasted marketing budget!</li>
                        <li><strong style="color: #c0392b;">False Negative (FN):</strong> Wrongly predicted "NO" - Missed good customers!</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="section">
            <div class="step-header">üìà Key Metrics Explained</div>
            
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="metric-title">üéØ Accuracy</div>
                    <div class="metric-formula">
                        (TP + TN) / (TP + TN + FP + FN)
                    </div>
                    <div class="metric-example">
                        (90 + 85) / 200 = 87.5%
                    </div>
                    <p><strong>Meaning:</strong> Overall correctness</p>
                </div>
                
                <div class="metric-card">
                    <div class="metric-title">üîç Precision</div>
                    <div class="metric-formula">
                        TP / (TP + FP)
                    </div>
                    <div class="metric-example">
                        90 / (90 + 15) = 85.7%
                    </div>
                    <p><strong>Meaning:</strong> Of all "YES" predictions, how many were correct?</p>
                </div>
                
                <div class="metric-card">
                    <div class="metric-title">üìä Recall (Sensitivity)</div>
                    <div class="metric-formula">
                        TP / (TP + FN)
                    </div>
                    <div class="metric-example">
                        90 / (90 + 10) = 90%
                    </div>
                    <p><strong>Meaning:</strong> Of all actual "YES" cases, how many did we find?</p>
                </div>
                
                <div class="metric-card">
                    <div class="metric-title">‚öñÔ∏è Specificity</div>
                    <div class="metric-formula">
                        TN / (TN + FP)
                    </div>
                    <div class="metric-example">
                        85 / (85 + 15) = 85%
                    </div>
                    <p><strong>Meaning:</strong> Of all actual "NO" cases, how many did we correctly identify?</p>
                </div>
            </div>
        </div>

        <div class="section">
            <div class="step-header">üìà ROC Curve & AUC - The Star Metric</div>
            
            <div class="auc-explanation">
                <h4>üåü Area Under ROC Curve (AUC) - What PySpark uses by default</h4>
                
                <div class="highlight">
                    <strong>ROC Curve:</strong> Plots True Positive Rate (Recall) vs False Positive Rate at different thresholds<br>
                    <strong>AUC:</strong> Area under this curve - single number summarizing model performance
                </div>
                
                <div class="roc-visualization">
                    <div class="roc-curve">
                        <div class="curve-perfect"></div>
                        <div class="axis-labels x-axis">False Positive Rate</div>
                        <div class="axis-labels y-axis">True Positive Rate</div>
                        <div style="position: absolute; bottom: -25px; left: 50%; transform: translateX(-50%); font-weight: bold; color: #27ae60;">Perfect Model (AUC = 1.0)</div>
                    </div>
                    
                    <div class="roc-curve">
                        <div class="curve-good"></div>
                        <div class="axis-labels x-axis">False Positive Rate</div>
                        <div class="axis-labels y-axis">True Positive Rate</div>
                        <div style="position: absolute; bottom: -25px; left: 50%; transform: translateX(-50%); font-weight: bold; color: #f39c12;">Good Model (AUC = 0.8)</div>
                    </div>
                    
                    <div class="roc-curve">
                        <div class="curve-random"></div>
                        <div class="axis-labels x-axis">False Positive Rate</div>
                        <div class="axis-labels y-axis">True Positive Rate</div>
                        <div style="position: absolute; bottom: -25px; left: 50%; transform: translateX(-50%); font-weight: bold; color: #e74c3c;">Random Guess (AUC = 0.5)</div>
                    </div>
                </div>
                
                <h5>üìè AUC Scale Interpretation:</h5>
                <div class="auc-scale">
                    <div class="scale-marker poor">0.5<br>Poor</div>
                    <div class="scale-marker fair">0.6<br>Fair</div>
                    <div class="scale-marker good">0.7<br>Good</div>
                    <div class="scale-marker excellent">0.9<br>Excellent</div>
                </div>
            </div>
        </div>

        <div class="section">
            <div class="step-header">üíª Using Binary Classification Evaluator in Code</div>
            
            <div class="code-block">
# Basic usage (default metric is AUC)
from pyspark.ml.evaluation import BinaryClassificationEvaluator

evaluator = BinaryClassificationEvaluator()
auc = evaluator.evaluate(predictions)
print(f"AUC: {auc:.3f}")

# Specify different metrics
evaluator_auc = BinaryClassificationEvaluator(metricName="areaUnderROC")
evaluator_pr = BinaryClassificationEvaluator(metricName="areaUnderPR")

auc_roc = evaluator_auc.evaluate(predictions)
auc_pr = evaluator_pr.evaluate(predictions)

print(f"Area Under ROC: {auc_roc:.3f}")
print(f"Area Under Precision-Recall: {auc_pr:.3f}")
            </div>
            
            <div class="visual-example">
                <h4>üîß Available Metrics:</h4>
                <ul>
                    <li><strong>"areaUnderROC"</strong> (default): Area under ROC curve</li>
                    <li><strong>"areaUnderPR"</strong>: Area under Precision-Recall curve</li>
                </ul>
                
                <h4>üìã Required Columns in your predictions DataFrame:</h4>
                <ul>
                    <li><strong>label:</strong> Actual values (0 or 1)</li>
                    <li><strong>rawPrediction:</strong> Raw model scores</li>
                    <li><strong>probability:</strong> Predicted probabilities (optional but recommended)</li>
                </ul>
            </div>
        </div>

        <div class="section">
            <div class="step-header">üéØ When to Use Which Metric</div>
            
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="metric-title">üìä AUC-ROC</div>
                    <p><strong>Best for:</strong> Balanced datasets</p>
                    <p><strong>Banking Use:</strong> Equal importance to finding customers and avoiding false alarms</p>
                    <p><strong>Range:</strong> 0.5 (random) to 1.0 (perfect)</p>
                </div>
                
                <div class="metric-card">
                    <div class="metric-title">üéØ AUC-PR</div>
                    <p><strong>Best for:</strong> Imbalanced datasets</p>
                    <p><strong>Banking Use:</strong> When most customers say "NO" (common scenario)</p>
                    <p><strong>Range:</strong> 0.0 to 1.0</p>
                </div>
            </div>
        </div>

        <div class="section">
            <div class="step-header">üí° Practical Tips for Students</div>
            
            <div class="highlight">
                <h4>üéì Key Takeaways:</h4>
                <ol>
                    <li><strong>AUC > 0.8:</strong> Your model is doing well!</li>
                    <li><strong>AUC > 0.9:</strong> Excellent performance (but check for overfitting)</li>
                    <li><strong>AUC < 0.6:</strong> Model needs improvement</li>
                    <li><strong>AUC = 0.5:</strong> Your model is no better than random guessing</li>
                    <li><strong>Always compare:</strong> Multiple models using the same evaluator</li>
                    <li><strong>Business context matters:</strong> Sometimes false positives cost more than false negatives (or vice versa)</li>
                </ol>
            </div>
            
            <div class="visual-example">
                <h4>üö® Common Mistakes to Avoid:</h4>
                <ul>
                    <li>‚ùå Using accuracy alone for imbalanced datasets</li>
                    <li>‚ùå Comparing AUC scores from different datasets</li>
                    <li>‚ùå Ignoring business costs of different error types</li>
                    <li>‚ùå Not checking if your predictions DataFrame has the right columns</li>
                    <li>‚úÖ Always use the same evaluator setup for fair comparison</li>
                </ul>
            </div>
        </div>
    </div>
</body>
</html>